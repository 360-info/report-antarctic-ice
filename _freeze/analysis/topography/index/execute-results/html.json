{
  "hash": "baaae28294caa735b2370a5067d8f81e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Untitled\nsubtitle: A slightly longer title\nformat:\n  360-analysis-html: default\nauthor: James Goldie\ndate: last-modified\ncode-fold: true\n---\n\n\n## Introduction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(terra)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nterra 1.7.65\n\nAttaching package: 'terra'\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(isoband)\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nhere() starts at /workspaces/report-antarctic-ice\n```\n\n\n:::\n:::\n\n\n# Bedmap2: Antarctic bed and land ice heights\n\nIf they aren't already present, we'll download the Bedmap2 topography/bathymetry grids, as well as the NSIC's median 1981-2010 sea ice borders for each month of the year:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndownload_if_not_present <- function(url, dest_zip, dest_dir,\n  temp_timeout = 3600) {\n  if (!file.exists(dest_zip)) {\n    message(paste0(\"Downloading data: \", basename(url), \"...\"))\n    old_timeout <- options(\"timeout\")\n    options(timeout = temp_timeout)\n    download.file(url, dest_zip)\n    unzip(dest_zip, exdir = dest_dir)\n    options(timeout = old_timeout)\n  } else {\n    message(\"Skipping download of \", basename(url))\n  }\n}\n\n# bedmap2:\n# - https://tc.copernicus.org/articles/7/375/2013/tc-7-375-2013.html\n# - https://secure.antarctica.ac.uk/data/bedmap2/\n# - readme: https://secure.antarctica.ac.uk/data/bedmap2/bedmap2_readme.txt\ndownload_if_not_present(\n  \"https://secure.antarctica.ac.uk/data/bedmap2/bedmap2_tiff.zip\",\n  here(\"data\", \"bedmap2.zip\"),\n  here(\"data\", \"bedmap2\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of bedmap2_tiff.zip\n```\n\n\n:::\n:::\n\n\nWe want to load these GeoTIFFs in to the browser, but they're way too big for users to download. Let's resample them to make smaller files:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load a GeoTIFF, shrink it and write the smaller version out\nshrink_raster <- function(x) {\n  here(\"data\", \"bedmap2\", \"bedmap2_tiff\", paste0(\"bedmap2_\", x, \".tif\")) |>\n    rast() |>\n    aggregate(fact = 15, fun = \"mean\") |>\n    # project(\"epsg:4326\", method = \"average\") |>\n    writeRaster(\n      here(\"data\", \"bedmap2\", paste0(\"bedmap2_\", x, \"_small.tif\")),\n      overwrite = TRUE)\n}\n\n# load a tiff, extract portion from specified height up, and write out as polys\nget_outlines <- function(x, height) {\n  here(\"data\", \"bedmap2\", \"bedmap2_tiff\", paste0(\"bedmap2_\", x, \".tif\")) |>\n    rast() |>\n    (\\(x)(x >= height))() |>\n    as.polygons() |>\n    subset(TRUE) |>\n    project(\"epsg:4326\") |>\n    writeVector(\n      here(\"data\", \"bedmap2\", paste0(\"bedmap2_\", x, \"_outline.geojson\")),\n      filetype = \"GeoJSON\",\n      overwrite = TRUE)\n}\n\n# run the above operations on our tiffs\nc(\"surface\", \"bed\", \"thickness\") |> walk(shrink_raster)\n\"surface\" |> walk2(0, get_outlines)\n\n# run off height levels at geojson vectors with {isoband} (cheers @mdsumner:\n# https://gist.github.com/mdsumner/53fc623ae740e02acc53fb923bf36128)\nisoband_terra_sf <- function(x, lo, hi, auto = FALSE) {\n  if (auto) {\n    breaks <- pretty(values(x), 10)\n    lo <- head(breaks, -1)\n    hi <- tail(breaks, -1)\n  }\n  ## OMG: note the [[1]] and wide = TRUE which is also weird but different\n  # to raster ...\n  b <- isoband::isobands(\n    xFromCol(x),\n    yFromRow(x),\n    as.matrix(x[[1]],\n    wide = TRUE),\n    levels_low = lo,\n    levels_hi = hi)\n  sf::st_sf(\n    lo = lo,\n    hi = hi,\n    geometry = sf::st_sfc(isoband::iso_to_sfg(b), crs = crs(x)))\n}\n\nhere(\"data\", \"bedmap2\", \"bedmap2_tiff\", paste0(\"bedmap2_bed.tif\")) |>\n  rast() |>\n  aggregate(fact = 15, fun = \"mean\") |>\n  (\\(x)(x %/% 100 * 100))() |>\n  isoband_terra_sf(auto = TRUE) ->\nbed_heights\n\nbed_heights |>\n  st_transform(st_crs(4326)) |>\n  write_sf(\n    here(\"data\", \"bedmap2\", paste0(\"bedmap2_bed_heights.geojson\")),\n    delete_dsn = TRUE)\n```\n:::\n\n\n:::{.callout-note}\nNote that `{isoband}` produces _left-handed_ polygons, which is [great for D3.js](https://gis.stackexchange.com/questions/392452/why-d3-js-works-only-with-geojson-violating-right-hand-rule) but might confuse some other tools.\n:::\n\n# NSIDC: median sea ice borders\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nsidc: sea ice index\n# https://nsidc.org/data/g02135/versions/3\n# shapefiles of median:\n#   https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/shapefiles/shp_median/\npadded_months <- 1:12 |> stringr::str_pad(2, pad = \"0\")\nnsidc_downloads <- tibble(\n  url = paste0(\n    \"https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/shapefiles/\",\n    \"shp_median/median_extent_S_\",\n    padded_months,\n    \"_1981-2010_polyline_v3.0.zip\"),\n  dest_zip = here(\"data\", \"nsidc\", paste0(\"seaice-\", padded_months, \".zip\")),\n  dest_dir = here(\"data\", \"nsidc\", paste0(\"seaice-\", padded_months)))\n\n# download all 12 files\npwalk(nsidc_downloads, download_if_not_present)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_01_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_02_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_03_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_04_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_05_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_06_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_07_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_08_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_09_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_10_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_11_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSkipping download of median_extent_S_12_1981-2010_polyline_v3.0.zip\n```\n\n\n:::\n:::\n\n\nThese are pretty tiny, so there's no need to simplify them. Instead, let's reproject them to EPSG:4326 and write them all out as a single GeoJSON:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# open all the months' boundaries in a single tibble\nnsidc_downloads |>\n  mutate(\n    month = padded_months,\n    dest_file =\n      file.path(dest_dir, basename(url)) |>\n      str_replace(\".zip\", \".shp\"),\n    shape = map(dest_file, read_sf)) |>\n  select(month, shape) ->\nseaice_shapes\n\n# convert to sf\nseaice_shapes |>\n  unnest(shape) |>\n  st_as_sf() ->\nseaice_sf\n\n# write out as geojson\nseaice_sf |>\n  st_transform(st_crs(4326)) |>\n  write_sf(here(\"data\", \"nsidc\", \"seaice_median.geojson\"), delete_dsn = TRUE)\n```\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}