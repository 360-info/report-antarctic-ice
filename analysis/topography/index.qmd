---
title: Untitled
subtitle: A slightly longer title
format:
  360-analysis-html: default
author: James Goldie
date: last-modified
code-fold: true
---

## Introduction

```{r}
#| label: setup

library(tidyverse)
library(sf)
library(terra)
library(isoband)
library(here)
```

# Bedmap2: Antarctic bed and land ice heights

If they aren't already present, we'll download the Bedmap2 topography/bathymetry grids, as well as the NSIC's median 1981-2010 sea ice borders for each month of the year:

```{r}
#| label: download-bedmap2
download_if_not_present <- function(url, dest_zip, dest_dir,
  temp_timeout = 3600) {
  if (!file.exists(dest_zip)) {
    message(paste0("Downloading data: ", basename(url), "..."))
    old_timeout <- options("timeout")
    options(timeout = temp_timeout)
    download.file(url, dest_zip)
    unzip(dest_zip, exdir = dest_dir)
    options(timeout = old_timeout)
  } else {
    message("Skipping download of ", basename(url))
  }
}

# bedmap2:
# - https://tc.copernicus.org/articles/7/375/2013/tc-7-375-2013.html
# - https://secure.antarctica.ac.uk/data/bedmap2/
# - readme: https://secure.antarctica.ac.uk/data/bedmap2/bedmap2_readme.txt
download_if_not_present(
  "https://secure.antarctica.ac.uk/data/bedmap2/bedmap2_tiff.zip",
  here("data", "bedmap2.zip"),
  here("data", "bedmap2"))
```

We want to load these GeoTIFFs in to the browser, but they're way too big for users to download. Let's resample them to make smaller files:

```{r}
#| label: process-tiffs

# load a GeoTIFF, shrink it and write the smaller version out
shrink_raster <- function(x) {
  here("data", "bedmap2", "bedmap2_tiff", paste0("bedmap2_", x, ".tif")) |>
    rast() |>
    aggregate(fact = 12, fun = "mean") |>
    # project("epsg:4326", method = "average") |>
    writeRaster(
      here("data", "bedmap2", paste0("bedmap2_", x, "_small.tif")),
      overwrite = TRUE)
}

# load a tiff, extract portion from specified height up, and write out as polys
get_outlines <- function(x, height) {
  here("data", "bedmap2", "bedmap2_tiff", paste0("bedmap2_", x, ".tif")) |>
    rast() |>
    (\(x)(x >= height))() |>
    as.polygons() |>
    subset(TRUE) |>
    project("epsg:4326") |>
    writeVector(
      here("data", "bedmap2", paste0("bedmap2_", x, "_outline.geojson")),
      filetype = "GeoJSON",
      overwrite = TRUE)
}

# run the above operations on our tiffs
c("surface", "bed", "thickness") |> walk(shrink_raster)
"surface" |> walk2(0, get_outlines)

# run off height levels at geojson vectors with {isoband} (cheers @mdsumner:
# https://gist.github.com/mdsumner/53fc623ae740e02acc53fb923bf36128)
isoband_terra_sf <- function(x, lo, hi, auto = FALSE) {
  if (auto) {
    breaks <- pretty(values(x), 10)
    lo <- head(breaks, -1)
    hi <- tail(breaks, -1)
  }
  ## OMG: note the [[1]] and wide = TRUE which is also weird but different
  # to raster ...
  b <- isoband::isobands(
    xFromCol(x),
    yFromRow(x),
    as.matrix(x[[1]],
    wide = TRUE),
    levels_low = lo,
    levels_hi = hi)
  sf::st_sf(
    lo = lo,
    hi = hi,
    geometry = sf::st_sfc(isoband::iso_to_sfg(b), crs = crs(x)))
}

here("data", "bedmap2", "bedmap2_tiff", paste0("bedmap2_bed.tif")) |>
  rast() |>
  aggregate(fact = 12, fun = "mean") |>
  (\(x)(x %/% 100 * 100))() |>
  isoband_terra_sf(auto = TRUE) ->
bed_heights

bed_heights |>
  st_transform(st_crs(4326)) |>
  write_sf(
    here("data", "bedmap2", paste0("bedmap2_bed_heights.geojson")),
    delete_dsn = TRUE)
```

:::{.callout-note}
Note that `{isoband}` produces _left-handed_ polygons, which is [great for D3.js](https://gis.stackexchange.com/questions/392452/why-d3-js-works-only-with-geojson-violating-right-hand-rule) but might confuse some other tools.
:::

# NSIDC: median sea ice borders

```{r}
#| label: download-nsidc

# nsidc: sea ice index
# https://nsidc.org/data/g02135/versions/3
# shapefiles of median:
#   https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/shapefiles/shp_median/
padded_months <- 1:12 |> stringr::str_pad(2, pad = "0")
nsidc_downloads <- tibble(
  url = paste0(
    "https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/shapefiles/",
    "shp_median/median_extent_S_",
    padded_months,
    "_1981-2010_polyline_v3.0.zip"),
  dest_zip = here("data", "nsidc", paste0("seaice-", padded_months, ".zip")),
  dest_dir = here("data", "nsidc", paste0("seaice-", padded_months)))

# download all 12 files
pwalk(nsidc_downloads, download_if_not_present)
```

These are pretty tiny, so there's no need to simplify them. Instead, let's reproject them to EPSG:4326 and write them all out as a single GeoJSON:

```{r}
#| label: process-nsidc

# open all the months' boundaries in a single tibble
nsidc_downloads |>
  mutate(
    month = padded_months,
    dest_file =
      file.path(dest_dir, basename(url)) |>
      str_replace(".zip", ".shp"),
    shape = map(dest_file, read_sf)) |>
  select(month, shape) ->
seaice_shapes

# convert to sf
seaice_shapes |>
  unnest(shape) |>
  st_as_sf() ->
seaice_sf

# write out as geojson
seaice_sf |>
  st_transform(st_crs(4326)) |>
  write_sf(here("data", "nsidc", "seaice_median.geojson"), delete_dsn = TRUE)

```