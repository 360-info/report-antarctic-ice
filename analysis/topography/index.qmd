---
title: Untitled
subtitle: A slightly longer title
format:
  360-analysis-html: default
author: James Goldie
date: last-modified
code-fold: true
---

## Introduction

```{r}
#| label: setup

library(tidyverse)
library(sf)
library(terra)
library(isoband)
library(here)
```

```{r}
#| label: fn-download-if-not-present
download_if_not_present <- function(url, dest_zip, dest_dir,
  temp_timeout = 3600) {
  if (!file.exists(dest_zip)) {
    message(paste0("Downloading data: ", basename(url), "..."))
    old_timeout <- options("timeout")
    options(timeout = temp_timeout)
    download.file(url, dest_zip)
    unzip(dest_zip, exdir = dest_dir)
    options(timeout = old_timeout)
  } else {
    message("Skipping download of ", basename(url))
  }
}
```

# Bedmap2: Antarctic bed and land ice heights

If they aren't already present, we'll download the Bedmap2 topography/bathymetry grids, as well as the NSIC's median 1981-2010 sea ice borders for each month of the year:

```{r}
#| label: download-bedmap2

# bedmap2:
# - https://tc.copernicus.org/articles/7/375/2013/tc-7-375-2013.html
# - https://secure.antarctica.ac.uk/data/bedmap2/
# - readme: https://secure.antarctica.ac.uk/data/bedmap2/bedmap2_readme.txt
download_if_not_present(
  "https://secure.antarctica.ac.uk/data/bedmap2/bedmap2_tiff.zip",
  here("data", "bedmap2.zip"),
  here("data", "bedmap2"))
```

We want to load these GeoTIFFs in to the browser, but they're way too big for users to download. Let's resample them to make smaller files:

```{r}
#| label: process-tiffs

# load a GeoTIFF, shrink it and write the smaller version out
shrink_raster <- function(x) {
  here("data", "bedmap2", "bedmap2_tiff", paste0("bedmap2_", x, ".tif")) |>
    rast() |>
    aggregate(fact = 15, fun = "mean") |>
    # project("epsg:4326", method = "average") |>
    writeRaster(
      here("data", "bedmap2", paste0("bedmap2_", x, "_small.tif")),
      overwrite = TRUE)
}

# load a tiff, extract portion from specified height up, and write out as polys
get_outlines <- function(x, height) {
  here("data", "bedmap2", "bedmap2_tiff", paste0("bedmap2_", x, ".tif")) |>
    rast() |>
    (\(x)(x >= height))() |>
    as.polygons() |>
    subset(TRUE) |>
    project("epsg:4326") |>
    writeVector(
      here("data", "bedmap2", paste0("bedmap2_", x, "_outline.geojson")),
      filetype = "GeoJSON",
      overwrite = TRUE)
}

# run the above operations on our tiffs
c("surface", "bed", "thickness") |> walk(shrink_raster)
"surface" |> walk2(0, get_outlines)

# run off height levels at geojson vectors with {isoband} (cheers @mdsumner:
# https://gist.github.com/mdsumner/53fc623ae740e02acc53fb923bf36128)
isoband_terra_sf <- function(x, lo, hi, auto = FALSE) {
  if (auto) {
    breaks <- pretty(values(x), 10)
    lo <- head(breaks, -1)
    hi <- tail(breaks, -1)
  }
  ## OMG: note the [[1]] and wide = TRUE which is also weird but different
  # to raster ...
  b <- isoband::isobands(
    xFromCol(x),
    yFromRow(x),
    as.matrix(x[[1]],
    wide = TRUE),
    levels_low = lo,
    levels_hi = hi)
  sf::st_sf(
    lo = lo,
    hi = hi,
    geometry = sf::st_sfc(isoband::iso_to_sfg(b), crs = crs(x)))
}

here("data", "bedmap2", "bedmap2_tiff", paste0("bedmap2_bed.tif")) |>
  rast() |>
  aggregate(fact = 15, fun = "mean") |>
  (\(x)(x %/% 100 * 100))() |>
  isoband_terra_sf(auto = TRUE) ->
bed_heights

bed_heights |>
  st_transform(st_crs(4326)) |>
  write_sf(
    here("data", "bedmap2", paste0("bedmap2_bed_heights.geojson")),
    delete_dsn = TRUE)
```

:::{.callout-note}
Note that `{isoband}` produces _left-handed_ polygons, which is [great for D3.js](https://gis.stackexchange.com/questions/392452/why-d3-js-works-only-with-geojson-violating-right-hand-rule) but might confuse some other tools.
:::

# NSIDC: median sea ice borders

```{r}
#| label: download-nsidc

# nsidc: sea ice index
# https://nsidc.org/data/g02135/versions/3
# shapefiles of median:
#   https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/shapefiles/shp_median/
padded_months <- 1:12 |> stringr::str_pad(2, pad = "0")
nsidc_downloads <- tibble(
  url = paste0(
    "https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/shapefiles/",
    "shp_median/median_extent_S_",
    padded_months,
    "_1981-2010_polyline_v3.0.zip"),
  dest_zip = here("data", "nsidc", paste0("seaice-", padded_months, ".zip")),
  dest_dir = here("data", "nsidc", paste0("seaice-", padded_months)))

# download all 12 files
pwalk(nsidc_downloads, download_if_not_present)
```

These are pretty tiny, so there's no need to simplify them. Instead, let's reproject them to EPSG:4326 and write them all out as a single GeoJSON:

```{r}
#| label: tidy-nsidc

# open all the months' boundaries in a single tibble
nsidc_downloads |>
  mutate(
    month = padded_months,
    dest_file =
      file.path(dest_dir, basename(url)) |>
      str_replace(".zip", ".shp"),
    shape = map(dest_file, read_sf)) |>
  select(month, shape) ->
seaice_shapes

# convert to sf
seaice_shapes |>
  unnest(shape) |>
  st_as_sf() ->
seaice_sf
```

These boundaries are line strings rather than polygons. We could make convex hulls of the boundaries, but we might miss areas where the sea ice boundaries curves back in toward the pole.

Instead, let's see what concave hulls look like:

```{r}
#| label: seaice-hulls

seaice_sf |>
  st_convex_hull() ->
seaice_hulls_convex

seaice_sf |>
  st_concave_hull(0.25, allow_holes = FALSE) ->
seaice_hulls_concave
```

```{r}
#| label: preview-seaice-hulls
# first the convex
ggplot() +
  geom_sf(data = seaice_hulls_convex, fill = "goldenrod") +
  geom_sf(data = seaice_hulls_concave) +
  geom_sf(data = seaice_sf) +
  facet_wrap(vars(month)) +
  theme_minimal()
```

This plot, showing the convex hulls (in yellow) and the concave ones at `ratio = 0.25` (in grey) agains tthe original boundaries, shows the concave hull is small but good improvement for most months.

It isn't working for Feb, though, so let's process that month separately with a higher `ratio` before returning it to the others.

```{r}
#| label: seaice-hull-feb

seaice_sf |>
  filter(month == "02") |>
  st_concave_hull(0.55, allow_holes = FALSE) ->
seaice_hull_feb

seaice_hulls_concave |>
  filter(month != "02") |>
  bind_rows(seaice_hull_feb) ->
seaice_hulls_final
```

And finally write both out as GeoJSON (after reprojecting to EPSG 4326):

```{r}
#| label: write-seaice
seaice_sf |>
  st_transform(st_crs(4326)) |>
  write_sf(here("data", "nsidc", "seaice_median.geojson"), delete_dsn = TRUE)

seaice_hulls_final |>
  st_transform(st_crs(4326)) |>
  write_sf(here("data", "nsidc", "seaice_median_hulls.geojson"), delete_dsn = TRUE)
```

# NSIDC: glaciers

The NSIDC's GLIMS dataset tracks glaciers. This time I've pre-downloaded the source point data and version controlled it; we'll crop it and re-export it as a CSV here.

```{r}
#| label: tidy-glims

here("data", "nsidc", "glaciers", "glims_points.shp") |>
  read_sf() |>
  # extract lat/lon for filtering (much easier than st_crop!)
  mutate(
    latlon = st_coordinates(geometry),
    lat = latlon[, "Y"],
    lon = latlon[, "X"]) |>
  filter(lat < -60) |>
  st_drop_geometry() |>
  select(-latlon) |>
  write_csv(here("data", "nsidc", "glaciers-antarctica.csv"))
```